{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6178741",
   "metadata": {},
   "source": [
    "Trusted Pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63f1811f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trusted pixels extraction\n",
    "def trustedPixels(year,gap):\n",
    "\n",
    "  def getCDLbyYear(year):\n",
    "      return ee.Image('USDA/NASS/CDL/'+year).select('cropland')\n",
    "\n",
    "  gap = gap - 1\n",
    "  # year = 2025\n",
    "  oneYearList = list(range(year-gap,year))\n",
    "  # print(oneYearList)\n",
    "  twoYearList = oneYearList[0:gap:2]\n",
    "  # print(twoYearList)\n",
    "\n",
    "  oneYearListCdl = ee.ImageCollection(list(map(getCDLbyYear, list(map(str, oneYearList)))))\n",
    "  twoYearListCdl = ee.ImageCollection(list(map(getCDLbyYear, list(map(str, twoYearList)))))\n",
    "  # display(oneYearListCdl,twoYearListCdl)\n",
    "\n",
    "  # Calculate the standard deviation across the ImageCollection to find constant pixels.\n",
    "  # Create a mask where the standard deviation is zero (constant pixels).\n",
    "  oneYearconstant_mask = oneYearListCdl.reduce(ee.Reducer.stdDev()).eq(0)\n",
    "  twoYearconstant_mask = twoYearListCdl.reduce(ee.Reducer.stdDev()).eq(0)\n",
    "\n",
    "  oneYearTrusted = twoYearListCdl.first().updateMask(oneYearconstant_mask)\n",
    "  twoYearTrusted = twoYearListCdl.first().updateMask(twoYearconstant_mask)\n",
    "  # display(oneYearTrusted,twoYearTrusted)\n",
    "\n",
    "  # Merge the two trusted images\n",
    "  UStrustedpixel = ee.ImageCollection([oneYearTrusted, twoYearTrusted]).mosaic()\n",
    "\n",
    "  return UStrustedpixel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cc2f79",
   "metadata": {},
   "source": [
    "Function - L89 single classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd5a272d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single L89 tile classification\n",
    "def imgL89Classified(tile, startDate, endDate, cloudCover, CONUStrainingLabel):\n",
    "  # single tile path and row number\n",
    "  # L89_single = ee.List(tile)\n",
    "  path = tile[0] #L89_single.get(0)\n",
    "  row = tile[1] #L89_single.get(1)\n",
    "\n",
    "  # image selection\n",
    "  bands = ['SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7', 'NDVI', 'NDWI']\n",
    "  L8 = (ee.ImageCollection('LANDSAT/LC08/C02/T1_L2')\n",
    "                  .filterDate(startDate,endDate)\n",
    "                  .filter(ee.Filter.eq('WRS_PATH',path))\n",
    "                  .filter(ee.Filter.eq('WRS_ROW',row))\n",
    "                  .filter(ee.Filter.lt('CLOUD_COVER_LAND',cloudCover)))\n",
    "\n",
    "  L9 = (ee.ImageCollection('LANDSAT/LC09/C02/T1_L2')\n",
    "                  .filterDate(startDate,endDate)\n",
    "                  .filter(ee.Filter.eq('WRS_PATH',path))\n",
    "                  .filter(ee.Filter.eq('WRS_ROW',row))\n",
    "                  .filter(ee.Filter.lt('CLOUD_COVER_LAND',cloudCover)))\n",
    "\n",
    "  L89 = (ee.ImageCollection(L8.merge(L9)).sort('system:time_start')\n",
    "                                        .map(lambda image: image.addBands(image.normalizedDifference(['SR_B5','SR_B4']).rename('NDVI'))\n",
    "                                                                .addBands(image.normalizedDifference(['SR_B3','SR_B5']).rename('NDWI')))\n",
    "                                        .select(bands))\n",
    "\n",
    "  # convert ImageCollection to single Image\n",
    "  tileImage = L89.toBands()\n",
    "  # extract tile geometry\n",
    "  tileGeometry = tileImage.geometry()\n",
    "  # display(tileGeometry)\n",
    "  # bools = ee.Number(tileGeometry.area(1)).eq(0)\n",
    "  # display(bools)\n",
    "\n",
    "  output_description = str(path) + '_' + str(row) + '_' + endDate\n",
    "\n",
    "  # classification processing\n",
    "  def imgClassified():\n",
    "    # clip label image from trusted pixel raster\n",
    "    tileTrainingLabel = CONUStrainingLabel.clip(tileGeometry)\n",
    "    # training samples generation by stratified sampling method\n",
    "    trainingSample = tileImage.addBands(tileTrainingLabel).stratifiedSample(\n",
    "      numPoints = 2000,\n",
    "      classBand= 'cropland',\n",
    "      region= tileGeometry,\n",
    "      scale= 10\n",
    "    )\n",
    "\n",
    "    def couldClassified():\n",
    "      classified = (tileImage.classify(ee.Classifier.smileRandomForest(20).train(\n",
    "                                      features= trainingSample,\n",
    "                                      classProperty= 'cropland',\n",
    "                                      inputProperties= tileImage.bandNames()\n",
    "                                    )\n",
    "                            )\n",
    "                      .clip(tileGeometry)\n",
    "                      .set('type','classification')\n",
    "                      .toUint8()\n",
    "              )\n",
    "      majority_filtered = classified.focal_mode(\n",
    "          radius=1, # radius in pixels (1 = 3x3 window)\n",
    "          units='pixels',\n",
    "          kernelType='square',\n",
    "          iterations=1\n",
    "      )\n",
    "      output_dictionary = ee.Dictionary({'image':majority_filtered, 'description':output_description, 'region':tileGeometry})\n",
    "      return output_dictionary\n",
    "\n",
    "    def couldNotClassified():\n",
    "      # nullImg = ee.Image(0).clip(tileGeometry).set('type','null')\n",
    "      output_dictionary = ee.Dictionary({'image':'null', 'description':'null', 'region':'null'})\n",
    "      return output_dictionary\n",
    "\n",
    "\n",
    "    return ee.Algorithms.If(trainingSample.size().neq(0).And(trainingSample.aggregate_count_distinct(\"cropland\").neq(1)),couldClassified(),couldNotClassified())\n",
    "\n",
    "  # alternative null image process\n",
    "  def imgNull():\n",
    "    # nullImg = ee.Image(0).set('type','null') #.clip(tileGeometry)\n",
    "    output_dictionary = ee.Dictionary({'image':'null', 'description':'null', 'region':'null'})\n",
    "    return output_dictionary\n",
    "\n",
    "  # output classified crop map\n",
    "\n",
    "  return ee.Algorithms.If(ee.Number(tileGeometry.area(1)).neq(0),imgClassified(),imgNull())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36be3be",
   "metadata": {},
   "source": [
    "Function - L89 tile list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79875fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L89List(CONUSBoundary):\n",
    "  # Filter the L89 harmonized collection by date and bounds.\n",
    "  L8 = (ee.ImageCollection('LANDSAT/LC08/C02/T1_L2')\n",
    "                    .filterDate(\"2025-05-01\",\"2025-05-20\")\n",
    "                    .filterBounds(CONUSBoundary))\n",
    "  L9 = (ee.ImageCollection('LANDSAT/LC09/C02/T1_L2')\n",
    "                  .filterDate(\"2025-05-01\",\"2025-05-20\")\n",
    "                  .filterBounds(CONUSBoundary))\n",
    "\n",
    "  L89 = ee.ImageCollection(L8.merge(L9))\n",
    "\n",
    "  pathString = ee.Array(L89.aggregate_array('WRS_PATH'))\n",
    "  rowString = ee.Array(L89.aggregate_array('WRS_ROW'))\n",
    "  L89_pathrowlist = ee.Array.cat([pathString, rowString], 1).toList().distinct().getInfo()\n",
    "  return L89_pathrowlist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c298e13",
   "metadata": {},
   "source": [
    "Function - L89 mosaic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba856b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mosaicL89outputVRT(inputfolder_path,outputfolder_path,month):\n",
    "    # Build full folder path\n",
    "    # inputfolder_path = os.path.join('/content/drive/MyDrive', inputfolder)\n",
    "    # print(f\"Input folder path: {inputfolder_path}\")\n",
    "    # Find all .tif files in the folder\n",
    "    tif_files = glob.glob(os.path.join(inputfolder_path, '*.tif'))\n",
    "    print(f\"Found {len(tif_files)} files for mosaicking.\")\n",
    "\n",
    "    if not tif_files:\n",
    "        print(\"No .tif files found.\")\n",
    "        return\n",
    "\n",
    "    # Create temporary VRT (Virtual Raster Tile)\n",
    "    vrt_path = os.path.join(inputfolder_path, \"temp_mosaic.vrt\")\n",
    "    vrt_options = gdal.BuildVRTOptions(srcNodata=0, VRTNodata=0)\n",
    "    vrt = gdal.BuildVRT(vrt_path, tif_files, options=vrt_options)\n",
    "    if vrt is None:\n",
    "        print(\"VRT build failed.\")\n",
    "        return\n",
    "    vrt = None  # Close the VRT handle\n",
    "\n",
    "    # Define output mosaic path\n",
    "    # outputfolder_path = os.path.join('/content/drive/MyDrive', outputfolder)\n",
    "    os.makedirs(outputfolder_path, exist_ok=True)\n",
    "    out_fp = os.path.join(outputfolder_path, month+\"_L89mosaic.tif\")\n",
    "\n",
    "    # Translate VRT to compressed GeoTIFF using tiling and LZW compression\n",
    "    translate_options = gdal.TranslateOptions(\n",
    "        format='GTiff',\n",
    "        creationOptions=[\n",
    "            'TILED=YES',\n",
    "            'COMPRESS=LZW',\n",
    "            'BIGTIFF=YES',  # Use for large outputs\n",
    "            'NUM_THREADS=ALL_CPUS'\n",
    "        ]\n",
    "    )\n",
    "    gdal.Translate(out_fp, vrt_path, options=translate_options)\n",
    "    print(f\"Mosaic written to: {out_fp}\")\n",
    "\n",
    "    # Optional: remove temporary VRT\n",
    "    os.remove(vrt_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6106ec5",
   "metadata": {},
   "source": [
    "Download all files in the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc980cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_all_files_in_folder(service, folder_id):\n",
    "    query = f\"'{folder_id}' in parents and trashed=false\"\n",
    "    files = []\n",
    "    page_token = None\n",
    "\n",
    "    while True:\n",
    "        response = service.files().list(\n",
    "            q=query,\n",
    "            spaces='drive',\n",
    "            fields=\"nextPageToken, files(id, name)\",\n",
    "            pageSize=1000,\n",
    "            pageToken=page_token\n",
    "        ).execute()\n",
    "\n",
    "        files.extend(response.get('files', []))\n",
    "        page_token = response.get('nextPageToken', None)\n",
    "\n",
    "        if page_token is None:\n",
    "            break\n",
    "\n",
    "    return files\n",
    "\n",
    "\n",
    "# create service account key in Google Cloud, download key .json, share downloadable folders to created service account\n",
    "def downloadfiles_byserviceaccout(target_name, local_folder):\n",
    "    # Load your service account key\n",
    "    SERVICE_ACCOUNT_FILE = 'ee-huil7073-81b7212a3bd2.json'\n",
    "    SCOPES = ['https://www.googleapis.com/auth/drive']\n",
    "\n",
    "    creds = service_account.Credentials.from_service_account_file(\n",
    "        SERVICE_ACCOUNT_FILE, scopes=SCOPES)\n",
    "\n",
    "    drive_service = build('drive', 'v3', credentials=creds)\n",
    "\n",
    "    # List shared files\n",
    "    results = drive_service.files().list(q=f\"name = '{target_name}' and trashed = false\", pageSize=10, fields=\"files(id, name)\").execute()\n",
    "    print('results',results.get('files'))\n",
    "\n",
    "    # search and download each file in every folder\n",
    "    for f in results['files']:\n",
    "        folder_name = f['name']\n",
    "        folder_id = f['id']\n",
    "        print(\"folder_id\",folder_id)\n",
    "        \n",
    "        # create local folder \n",
    "        local_file_path = os.path.join(local_folder, folder_name)\n",
    "        os.makedirs(local_file_path, exist_ok=True)\n",
    "        print('local_file_path',local_file_path)\n",
    "\n",
    "        # Search for all files in this Drive folder\n",
    "        query = f\"'{folder_id}' in parents and trashed = false\"\n",
    "        filesList = list_all_files_in_folder(drive_service, folder_id)\n",
    "        print('filesList',len(filesList))\n",
    "        if len(filesList) == 0:\n",
    "             break\n",
    "\n",
    "        for i, file_obj in enumerate(filesList):\n",
    "                file_title = file_obj['name']\n",
    "                file_id = file_obj['id']\n",
    "                print(f\"{i+1}. {file_title} ({file_id})\")\n",
    "                local_file_name = os.path.join(local_file_path, file_title)\n",
    "\n",
    "                request = drive_service.files().get_media(fileId=file_id)\n",
    "                fh = io.FileIO(local_file_name, 'wb')\n",
    "                downloader = MediaIoBaseDownload(fh, request)\n",
    "                done = False\n",
    "                while done is False:\n",
    "                    status, done = downloader.next_chunk()\n",
    "                    print(f\"Download {int(status.progress() * 100)}%.\")\n",
    "\n",
    "        print(f\"All files downloaded to: {local_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94b4311",
   "metadata": {},
   "source": [
    "Function - L89 mosaic mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428e92d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L89MosaicClassification(startDate, endDate, month, cloudCover, CONUSBoundary, CONUStrainingLabel, tileFolder, local_root_folder, mosaicFolder):\n",
    "  \n",
    "  # Filter the L89 harmonized collection by date and bounds.\n",
    "  pathrowlist = L89List(CONUSBoundary)\n",
    "  numList = len(pathrowlist)\n",
    "  print('Number of L89 tiles:',numList)\n",
    "\n",
    "  taskList = []\n",
    "\n",
    "  # classification for each single tile\n",
    "#   for i in range(numList):\n",
    "  for i in range(0,1):\n",
    "    tile = pathrowlist[i]\n",
    "    print(i, tile)\n",
    "    classified_dictionary = ee.Dictionary(imgL89Classified(tile, startDate, endDate, cloudCover, CONUStrainingLabel))\n",
    "    # display(classified_dictionary)\n",
    "    imgID =classified_dictionary.get('description').getInfo()\n",
    "    print('imgID',imgID)\n",
    "    if imgID != 'null':\n",
    "      classified =ee.Image(classified_dictionary.get('image'))\n",
    "      refion = ee.Geometry(classified_dictionary.get('region'))\n",
    "      description = month + '_' + classified_dictionary.get('description').getInfo()\n",
    "\n",
    "      task = ee.batch.Export.image.toDrive(\n",
    "          image = classified,\n",
    "          description = description,\n",
    "          folder = tileFolder,\n",
    "          region = refion, # Ensure region is a list of coordinates\n",
    "          scale = 10, # Resolution of your output image\n",
    "          crs = 'EPSG:5070', # Coordinate Reference System\n",
    "          maxPixels = 1e12 # Increase if you encounter \"Too many pixels\" error\n",
    "      )\n",
    "      task.start()\n",
    "      taskList.append(task)\n",
    "      print(f\"Export task '{classified_dictionary.get('description').getInfo()}' started. Check Google Drive {tileFolder} folder.\")\n",
    "\n",
    "  # Function to monitor task completion\n",
    "  def wait_for_tasks(tasks):\n",
    "      print(\"Waiting for all export tasks to complete...\")\n",
    "      while True:\n",
    "          statuses = [task.status()['state'] for task in tasks]\n",
    "          print(statuses)  # Optional: track task progress\n",
    "          if all(state in ['COMPLETED', 'FAILED', 'CANCELLED'] for state in statuses):\n",
    "              break\n",
    "          time.sleep(30)  # Wait 30 seconds before checking again\n",
    "\n",
    "  # Call the monitoring function\n",
    "  wait_for_tasks(taskList)\n",
    "\n",
    "  # download all classified images when finishing upload  \n",
    "  # time.sleep(30) # Wait for 30 seconds before checking again\n",
    "  downloadfiles_byserviceaccout(tileFolder, local_root_folder)\n",
    "\n",
    "  # mosaic all classified images when finishing download\n",
    "  # time.sleep(30) # Wait for 30 seconds before checking again\n",
    "  print(\"Ready to mosaic\")\n",
    "  sourceFolder = os.path.join(local_root_folder, tileFolder)\n",
    "  mosaicL89outputVRT(sourceFolder, mosaicFolder, month)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f80e63",
   "metadata": {},
   "source": [
    "Application - L89 mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aea0699b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results [{'id': '1fs7VGAk4o7rhWUkHoIJd6LV6_8epSXzu', 'name': 'AutoInseasonL89_MappingTest'}, {'id': '1ZaoeDSWaRyYir9iLzaUaxfxVxY0NyIt3', 'name': 'AutoInseasonL89_MappingTest'}]\n",
      "folder_id 1fs7VGAk4o7rhWUkHoIJd6LV6_8epSXzu\n",
      "local_file_path ../DownloadClassifications\\AutoInseasonL89_MappingTest\n",
      "filesList 2\n",
      "1. Copy of June_11_29_2025-07-01.tif (16se_NDW3gaFXvc8Awj5fA7ky1F4T8a7N)\n",
      "Download 100%.\n",
      "2. Copy of June_10_28_2025-07-01.tif (1dGKa3dDjYPppF_9tkqMa3GgJr-Hd0-zT)\n",
      "Download 100%.\n",
      "All files downloaded to: ../DownloadClassifications\\AutoInseasonL89_MappingTest\n",
      "folder_id 1ZaoeDSWaRyYir9iLzaUaxfxVxY0NyIt3\n",
      "local_file_path ../DownloadClassifications\\AutoInseasonL89_MappingTest\n",
      "filesList 0\n",
      "Ready to mosaic\n",
      "Found 2 files for mosaicking.\n",
      "Mosaic written to: ../DownloadClassifications/AutoInseasonL89S2_Mosaic\\June_L89mosaic.tif\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "from osgeo import gdal\n",
    "import ee\n",
    "import io\n",
    "from google.oauth2 import service_account\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "\n",
    "# Path to your downloaded JSON key\n",
    "SERVICE_ACCOUNT = 'automatedmapping@ee-huil7073.iam.gserviceaccount.com'\n",
    "KEY_FILE = 'ee-huil7073-81b7212a3bd2.json'\n",
    "\n",
    "credentials = ee.ServiceAccountCredentials(SERVICE_ACCOUNT, KEY_FILE)\n",
    "ee.Initialize(credentials)\n",
    "\n",
    "CONUSBoundary = (ee.FeatureCollection(\"TIGER/2018/States\")\n",
    "                    .filter(ee.Filter.eq('NAME', 'Nebraska'))).geometry()\n",
    "\n",
    "CONUStrainingLabel = trustedPixels(2025,7)\n",
    "\n",
    "startDate = \"2025-05-01\"\n",
    "endDate = \"2025-07-01\"\n",
    "month = \"June\"\n",
    "cloudCover = 20\n",
    "\n",
    "\n",
    "# root_path = '/content/drive/MyDrive/'\n",
    "L89tileFolder = 'AutoInseasonL89_MappingTest'\n",
    "S2tileFolder = 'AutoInseasonS2_MappingTest'\n",
    "local_root_folder = '../DownloadClassifications'\n",
    "mosaicfolder_path = '../DownloadClassifications/AutoInseasonL89S2_Mosaic'\n",
    "\n",
    "L89MosaicClassification(startDate, endDate, month, cloudCover, CONUSBoundary, CONUStrainingLabel, L89tileFolder, local_root_folder, mosaicfolder_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

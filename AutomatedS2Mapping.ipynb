{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e133b2b1",
   "metadata": {},
   "source": [
    "Trusted Pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8c4b36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trusted pixels extraction\n",
    "def trustedPixels(year,gap):\n",
    "\n",
    "  def getCDLbyYear(year):\n",
    "      return ee.Image('USDA/NASS/CDL/'+year).select('cropland')\n",
    "\n",
    "  gap = gap - 1\n",
    "  # year = 2025\n",
    "  oneYearList = list(range(year-gap,year))\n",
    "  # print(oneYearList)\n",
    "  twoYearList = oneYearList[0:gap:2]\n",
    "  # print(twoYearList)\n",
    "\n",
    "  oneYearListCdl = ee.ImageCollection(list(map(getCDLbyYear, list(map(str, oneYearList)))))\n",
    "  twoYearListCdl = ee.ImageCollection(list(map(getCDLbyYear, list(map(str, twoYearList)))))\n",
    "  # display(oneYearListCdl,twoYearListCdl)\n",
    "\n",
    "  # Calculate the standard deviation across the ImageCollection to find constant pixels.\n",
    "  # Create a mask where the standard deviation is zero (constant pixels).\n",
    "  oneYearconstant_mask = oneYearListCdl.reduce(ee.Reducer.stdDev()).eq(0)\n",
    "  twoYearconstant_mask = twoYearListCdl.reduce(ee.Reducer.stdDev()).eq(0)\n",
    "\n",
    "  oneYearTrusted = twoYearListCdl.first().updateMask(oneYearconstant_mask)\n",
    "  twoYearTrusted = twoYearListCdl.first().updateMask(twoYearconstant_mask)\n",
    "  # display(oneYearTrusted,twoYearTrusted)\n",
    "\n",
    "  # Merge the two trusted images\n",
    "  UStrustedpixel = ee.ImageCollection([oneYearTrusted, twoYearTrusted]).mosaic()\n",
    "\n",
    "  return UStrustedpixel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19129756",
   "metadata": {},
   "source": [
    "Function - S2 single classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0211341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single S2 tile classification\n",
    "def imgS2Classified(tile, startDate, endDate, cloudCover, CONUStrainingLabel):\n",
    "  # image selection\n",
    "  bands = ['B2', 'B3', 'B4', 'B8', 'B11', 'B12', 'NDVI', 'NDWI']\n",
    "  S2  = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "                        .filter(ee.Filter.eq('MGRS_TILE', tile))\n",
    "                        .filterDate(startDate, endDate)\n",
    "                        .filter(ee.Filter.lt('NODATA_PIXEL_PERCENTAGE',10))\n",
    "                        .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE',cloudCover))\n",
    "                        .map(lambda image: image.addBands(image.normalizedDifference(['B8', 'B4']).rename('NDVI'))\n",
    "                                                .addBands(image.normalizedDifference(['B3', 'B8']).rename('NDWI')))\n",
    "                        .select(bands)\n",
    "                        )\n",
    "\n",
    "  # convert ImageCollection to single Image\n",
    "  tileImage = S2.toBands()\n",
    "  # extract tile geometry\n",
    "  tileGeometry = tileImage.geometry()\n",
    "  # display(tileGeometry)\n",
    "  # bools = ee.Number(tileGeometry.area(1)).eq(0)\n",
    "  # display(bools)\n",
    "\n",
    "  output_description = str(tile) + '_' + endDate\n",
    "\n",
    "  # classification processing\n",
    "  def imgClassified():\n",
    "    # clip label image from trusted pixel raster\n",
    "    tileTrainingLabel = CONUStrainingLabel.clip(tileGeometry)\n",
    "    # training samples generation by stratified sampling method\n",
    "    trainingSample = tileImage.addBands(tileTrainingLabel).stratifiedSample(\n",
    "      numPoints = 1800,\n",
    "      classBand= 'cropland',\n",
    "      region= tileGeometry,\n",
    "      scale= 10\n",
    "    )\n",
    "\n",
    "    def couldClassified():\n",
    "      classified = (tileImage.classify(ee.Classifier.smileRandomForest(20).train(\n",
    "                                      features= trainingSample,\n",
    "                                      classProperty= 'cropland',\n",
    "                                      inputProperties= tileImage.bandNames()\n",
    "                                    )\n",
    "                            )\n",
    "                      .clip(tileGeometry)\n",
    "                      .set('type','classification')\n",
    "                      .toUint8()\n",
    "              )\n",
    "      majority_filtered = classified.focal_mode(\n",
    "        radius=1, # radius in pixels (1 = 3x3 window)\n",
    "        units='pixels',\n",
    "        kernelType='square',\n",
    "        iterations=1\n",
    "      )\n",
    "      output_dictionary = ee.Dictionary({'image':majority_filtered, 'description':output_description, 'region':tileGeometry})\n",
    "      return output_dictionary\n",
    "\n",
    "    def couldNotClassified():\n",
    "      # nullImg = ee.Image(0).clip(tileGeometry).set('type','null')\n",
    "      output_dictionary = ee.Dictionary({'image':'null', 'description':'null', 'region':'null'})\n",
    "      return output_dictionary\n",
    "\n",
    "\n",
    "    return ee.Algorithms.If(trainingSample.size().neq(0).And(trainingSample.aggregate_count_distinct(\"cropland\").neq(1)),couldClassified(),couldNotClassified())\n",
    "\n",
    "  # alternative null image process\n",
    "  def imgNull():\n",
    "    # nullImg = ee.Image(0).set('type','null') #.clip(tileGeometry)\n",
    "    output_dictionary = ee.Dictionary({'image':'null', 'description':'null', 'region':'null'})\n",
    "    return output_dictionary\n",
    "\n",
    "  # output classified crop map\n",
    "\n",
    "  return ee.Algorithms.If(ee.Number(tileGeometry.area(1)).neq(0),imgClassified(),imgNull())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e16251",
   "metadata": {},
   "source": [
    "Function - S2 state tile list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b91b645",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stateS2List(CONUSBoundary):\n",
    "  # Filter the S2 harmonized collection by date and bounds.\n",
    "  S2_tilelist = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "                              .filterDate(\"2025-05-01\", \"2025-05-15\")\n",
    "                              .filterBounds(CONUSBoundary)\n",
    "                              .aggregate_array('MGRS_TILE')\n",
    "                              .distinct()\n",
    "                              .getInfo())\n",
    "  return S2_tilelist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8dc240",
   "metadata": {},
   "source": [
    "Function - S2 mosaic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cde6772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mosaicS2outputVRT(inputfolder_path,outputfolder_path,month):\n",
    "    # Build full folder path\n",
    "    # inputfolder_path = os.path.join('/content/drive/MyDrive', inputfolder)\n",
    "    # print(f\"Input folder path: {inputfolder_path}\")\n",
    "    # Find all .tif files in the folder\n",
    "    tif_files = glob.glob(os.path.join(inputfolder_path, '*.tif'))\n",
    "    print(f\"Found {len(tif_files)} files for mosaicking.\")\n",
    "\n",
    "    if not tif_files:\n",
    "        print(\"No .tif files found.\")\n",
    "        return\n",
    "\n",
    "    # Create temporary VRT (Virtual Raster Tile)\n",
    "    vrt_path = os.path.join(inputfolder_path, \"temp_mosaic.vrt\")\n",
    "    vrt_options = gdal.BuildVRTOptions(srcNodata=0, VRTNodata=0)\n",
    "    vrt = gdal.BuildVRT(vrt_path, tif_files, options=vrt_options)\n",
    "    if vrt is None:\n",
    "        print(\"VRT build failed.\")\n",
    "        return\n",
    "    vrt = None  # Close the VRT handle\n",
    "\n",
    "    # Define output mosaic path\n",
    "    # outputfolder_path = os.path.join('/content/drive/MyDrive', outputfolder)\n",
    "    os.makedirs(outputfolder_path, exist_ok=True)\n",
    "    out_fp = os.path.join(outputfolder_path, month+\"_S2mosaic.tif\")\n",
    "\n",
    "    # Translate VRT to compressed GeoTIFF using tiling and LZW compression\n",
    "    translate_options = gdal.TranslateOptions(\n",
    "        format='GTiff',\n",
    "        creationOptions=[\n",
    "            'TILED=YES',\n",
    "            'COMPRESS=LZW',\n",
    "            'BIGTIFF=YES',  # Use for large outputs\n",
    "            'NUM_THREADS=ALL_CPUS'\n",
    "        ]\n",
    "    )\n",
    "    gdal.Translate(out_fp, vrt_path, options=translate_options)\n",
    "    print(f\"Mosaic written to: {out_fp}\")\n",
    "\n",
    "    # Optional: remove temporary VRT\n",
    "    os.remove(vrt_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8dd86b",
   "metadata": {},
   "source": [
    "Download all files in the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20115a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_all_files_in_folder(service, folder_id):\n",
    "    query = f\"'{folder_id}' in parents and trashed=false\"\n",
    "    files = []\n",
    "    page_token = None\n",
    "\n",
    "    while True:\n",
    "        response = service.files().list(\n",
    "            q=query,\n",
    "            spaces='drive',\n",
    "            fields=\"nextPageToken, files(id, name)\",\n",
    "            pageSize=1000,\n",
    "            pageToken=page_token\n",
    "        ).execute()\n",
    "\n",
    "        files.extend(response.get('files', []))\n",
    "        page_token = response.get('nextPageToken', None)\n",
    "\n",
    "        if page_token is None:\n",
    "            break\n",
    "\n",
    "    return files\n",
    "\n",
    "\n",
    "# create service account key in Google Cloud, download key .json, share downloadable folders to created service account\n",
    "def downloadfiles_byserviceaccout(target_name, local_folder):\n",
    "    # Load your service account key\n",
    "    SERVICE_ACCOUNT_FILE = 'ee-huil7073-81b7212a3bd2.json'\n",
    "    SCOPES = ['https://www.googleapis.com/auth/drive']\n",
    "\n",
    "    creds = service_account.Credentials.from_service_account_file(\n",
    "        SERVICE_ACCOUNT_FILE, scopes=SCOPES)\n",
    "\n",
    "    drive_service = build('drive', 'v3', credentials=creds)\n",
    "\n",
    "    # List shared files\n",
    "    results = drive_service.files().list(q=f\"name = '{target_name}' and trashed = false\", pageSize=10, fields=\"files(id, name)\").execute()\n",
    "    print('results',results.get('files'))\n",
    "\n",
    "    # search and download each file in every folder\n",
    "    for f in results['files']:\n",
    "        folder_name = f['name']\n",
    "        folder_id = f['id']\n",
    "        print(\"folder_id\",folder_id)\n",
    "        \n",
    "        # create local folder \n",
    "        local_file_path = os.path.join(local_folder, folder_name)\n",
    "        os.makedirs(local_file_path, exist_ok=True)\n",
    "        print('local_file_path',local_file_path)\n",
    "\n",
    "        # Search for all files in this Drive folder\n",
    "        query = f\"'{folder_id}' in parents and trashed = false\"\n",
    "        filesList = list_all_files_in_folder(drive_service, folder_id)\n",
    "        print('filesList',len(filesList))\n",
    "        if len(filesList) == 0:\n",
    "            break\n",
    "        for i, file_obj in enumerate(filesList):\n",
    "                file_title = file_obj['name']\n",
    "                file_id = file_obj['id']\n",
    "                print(f\"{i+1}. {file_title} ({file_id})\")\n",
    "                local_file_name = os.path.join(local_file_path, file_title)\n",
    "\n",
    "                request = drive_service.files().get_media(fileId=file_id)\n",
    "                fh = io.FileIO(local_file_name, 'wb')\n",
    "                downloader = MediaIoBaseDownload(fh, request)\n",
    "                done = False\n",
    "                while done is False:\n",
    "                    status, done = downloader.next_chunk()\n",
    "                    print(f\"Download {int(status.progress() * 100)}%.\")\n",
    "\n",
    "        print(f\"All files downloaded to: {local_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b04af9",
   "metadata": {},
   "source": [
    "Function - S2 mosaic mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a241da24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def S2MosaicClassification(startDate, endDate, month, cloudCover, CONUSBoundary, CONUStrainingLabel, tileFolder, local_root_folder, mosaicFolder):\n",
    "  \n",
    "  # Filter the S2 harmonized collection by date and bounds.\n",
    "  S2_tilelist = stateS2List(CONUSBoundary)\n",
    "  numList = len(S2_tilelist)\n",
    "  print('Number of S2 tiles:',numList)\n",
    "\n",
    "  taskList = []\n",
    "\n",
    "  # classification for each single tile\n",
    "  # for i in range(935,numList):\n",
    "  for i in range(0,1):\n",
    "    tile = S2_tilelist[i]\n",
    "    print(i, tile)\n",
    "    classified_dictionary = ee.Dictionary(imgS2Classified(tile, startDate, endDate, cloudCover, CONUStrainingLabel))\n",
    "    # display(classified_dictionary)\n",
    "    imgID =classified_dictionary.get('description').getInfo()\n",
    "    # print('ifnull',ifnull)\n",
    "    if imgID != 'null':\n",
    "      classified =ee.Image(classified_dictionary.get('image'))\n",
    "      refion = ee.Geometry(classified_dictionary.get('region'))\n",
    "      description = month+'_'+classified_dictionary.get('description').getInfo()\n",
    "\n",
    "      task = ee.batch.Export.image.toDrive(\n",
    "          image = classified,\n",
    "          description = description,\n",
    "          folder = tileFolder,\n",
    "          region = refion, # Ensure region is a list of coordinates\n",
    "          scale = 10, # Resolution of your output image\n",
    "          crs = 'EPSG:5070', # Coordinate Reference System\n",
    "          maxPixels = 1e12 # Increase if you encounter \"Too many pixels\" error\n",
    "      )\n",
    "      task.start()\n",
    "      taskList.append(task)\n",
    "      print(f\"Export task '{classified_dictionary.get('description').getInfo()}' started. Check Google Drive {tileFolder} folder.\")\n",
    "\n",
    "  # Function to monitor task completion\n",
    "  def wait_for_tasks(tasks):\n",
    "    print(\"Waiting for all export tasks to complete...\")\n",
    "    while True:\n",
    "        statuses = [task.status()['state'] for task in tasks]\n",
    "        print(statuses)  # Optional: track task progress\n",
    "        if all(state in ['COMPLETED', 'FAILED', 'CANCELLED'] for state in statuses):\n",
    "            break\n",
    "        time.sleep(30)  # Wait 30 seconds before checking again\n",
    "\n",
    "  # Call the monitoring function\n",
    "  wait_for_tasks(taskList)\n",
    "\n",
    "  # download all classified images when finishing upload  \n",
    "  # time.sleep(30) # Wait for 30 seconds before checking again\n",
    "  downloadfiles_byserviceaccout(tileFolder, local_root_folder)\n",
    "\n",
    "  # mosaic all classified images when finishing download\n",
    "  # time.sleep(30) # Wait for 30 seconds before checking again\n",
    "  print(\"Ready to mosaic\")\n",
    "  sourceFolder = os.path.join(local_root_folder, tileFolder)\n",
    "  mosaicS2outputVRT(sourceFolder, mosaicFolder, month)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5603161e",
   "metadata": {},
   "source": [
    "Application - S2 mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63583df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a geometry to cover Conterminous U.S.\n",
    "# CONUSBoundary = (ee.FeatureCollection(\"TIGER/2018/States\")\n",
    "#                     .filter(ee.Filter.neq('NAME', 'United States Virgin Islands'))\n",
    "#                     .filter(ee.Filter.neq('NAME', 'Puerto Rico'))\n",
    "#                     .filter(ee.Filter.neq('NAME', 'Alaska'))\n",
    "#                     .filter(ee.Filter.neq('NAME', 'Hawaii'))\n",
    "#                     .filter(ee.Filter.neq('NAME', 'Guam'))\n",
    "#                     .filter(ee.Filter.neq('NAME', 'Virgin Islands'))\n",
    "#                     .filter(ee.Filter.neq('NAME', 'American Samoa'))\n",
    "#                     .filter(ee.Filter.neq('NAME', 'Northern Mariana Islands'))\n",
    "#                     .filter(ee.Filter.neq('NAME', 'Commonwealth of the Northern Mariana Islands'))).union().geometry()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "932fe7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results [{'id': '1Hce2XiS1RFBOqRUd_G5rXPofuMSMSc8C', 'name': 'AutoInseasonS2_MappingTest'}]\n",
      "folder_id 1Hce2XiS1RFBOqRUd_G5rXPofuMSMSc8C\n",
      "local_file_path ../DownloadClassifications\\AutoInseasonS2_MappingTest\n",
      "filesList 2\n",
      "1. Copy of 10SDJ_2025-07-01_June.tif (1whOL0znO5N4LofMfs3pp_bni-aAW0I00)\n",
      "Download 100%.\n",
      "2. Copy of 10SDH_2025-07-01_June.tif (1equqkyCK4-CWsGvfTnBIG-JsrSNQd_P4)\n",
      "Download 100%.\n",
      "All files downloaded to: ../DownloadClassifications\\AutoInseasonS2_MappingTest\n",
      "Ready to mosaic\n",
      "Found 2 files for mosaicking.\n",
      "Mosaic written to: ../DownloadClassifications/AutoInseasonL89S2_Mosaic\\June_S2mosaic.tif\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "from osgeo import gdal\n",
    "import ee\n",
    "import io\n",
    "from google.oauth2 import service_account\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "\n",
    "# Path to your downloaded JSON key\n",
    "SERVICE_ACCOUNT = 'automatedmapping@ee-huil7073.iam.gserviceaccount.com'\n",
    "KEY_FILE = 'ee-huil7073-81b7212a3bd2.json'\n",
    "\n",
    "credentials = ee.ServiceAccountCredentials(SERVICE_ACCOUNT, KEY_FILE)\n",
    "ee.Initialize(credentials)\n",
    "\n",
    "CONUSBoundary = (ee.FeatureCollection(\"TIGER/2018/States\")\n",
    "                    .filter(ee.Filter.eq('NAME', 'Nebraska'))).geometry()\n",
    "\n",
    "CONUStrainingLabel = trustedPixels(2025,7)\n",
    "\n",
    "startDate = \"2025-05-01\"\n",
    "endDate = \"2025-07-01\"\n",
    "month = \"June\"\n",
    "cloudCover = 20\n",
    "\n",
    "\n",
    "# root_path = '/content/drive/MyDrive/'\n",
    "S2tileFolder = 'AutoInseasonS2_MappingTest'\n",
    "local_root_folder = '../DownloadClassifications'\n",
    "mosaicfolder_path = '../DownloadClassifications/AutoInseasonL89S2_Mosaic'\n",
    "\n",
    "S2MosaicClassification(startDate, endDate, month, cloudCover, CONUSBoundary, CONUStrainingLabel, S2tileFolder, local_root_folder, mosaicfolder_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
